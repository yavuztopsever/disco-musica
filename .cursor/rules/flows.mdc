---
description: flows
globs: 
alwaysApply: false
---
# Disco Musica Application Flows

This document outlines the current and planned flows in the Disco Musica application using Mermaid diagrams. It provides a comprehensive view of the system architecture, component interactions, and data flows.

## Table of Contents

1. [Application Core Flows](mdc:#application-core-flows)
2. [Generation Service Flows](mdc:#generation-service-flows)
3. [Model Service Flows](mdc:#model-service-flows)
4. [Data Processing Flows](mdc:#data-processing-flows)
5. [Training Service Flows](mdc:#training-service-flows)
6. [UI Flows](mdc:#ui-flows)
7. [Integration Flows](mdc:#integration-flows)
8. [Deployment Flows](mdc:#deployment-flows)

---

## Application Core Flows

### Main Application Startup Flow

```mermaid
flowchart TD
    A[main.py] --> B[parse_args]
    A --> C[setup_logging]
    A --> D[Initialize Services]
    D --> D1[model_service]
    D --> D2[generation_service]
    D --> D3[output_service]
    D --> D4[training_service]
    A --> E{mode?}
    E -->|UI| F[launch_ui]
    E -->|CLI| G[CLI mode]
    F --> H[create_ui]
    H --> I[Gradio Blocks Interface]
    I --> J1[Text to Music Tab]
    I --> J2[Audio to Music Tab]
    I --> J3[MIDI to Audio Tab]
    I --> J4[Image to Music Tab]
    I --> J5[Training Tab]
    I --> J6[Library Tab]
    I --> J7[Settings Tab]
```

### Configuration and Environment Flow

```mermaid
flowchart TD
    A[main.py] --> B[Load Environment Variables]
    A --> C[Load Config Files]
    C --> C1[config.yaml]
    C --> C2[user_config.yaml]
    C --> C3[.env file]
    A --> D[Setup Directories]
    D --> D1[Data Directory]
    D --> D2[Models Directory]
    D --> D3[Output Directory]
    D --> D4[Temp Directory]
    D --> D5[Log Directory]
    A --> E[Initialize Services]
    E --> E1[Check GPU]
    E --> E2[Check Audio Devices]
    E --> E3[Check Internet Connection]
    E --> E4[Validate Dependencies]
```

### Error Handling and Logging Flow

```mermaid
flowchart TD
    A[Application Operation] --> B{Exception?}
    B -->|Yes| C[Error Handler]
    C --> D[Log Error]
    D --> D1[Console Log]
    D --> D2[File Log]
    D --> D3[Error Stats]
    C --> E{Recoverable?}
    E -->|Yes| F[Recovery Routine]
    F --> G[Restart Component]
    F --> H[Fallback Mode]
    E -->|No| I[User Error Message]
    I --> J[Detailed View Toggle]
    I --> K[Report Issue Option]
    B -->|No| L[Normal Operation]
```

---

## Generation Service Flows

### Text-to-Music Generation Flow

```mermaid
flowchart TD
    A[User Input] --> B[Text Prompt]
    A --> C[Model Selection]
    A --> D[Parameters]
    D --> D1[Duration]
    D --> D2[Temperature]
    D --> D3[Seed]
    D --> D4[Top-k]
    D --> D5[Top-p]
    D --> D6[Guidance Scale]
    B & C & D --> E[Generate Button]
    E --> F[generate_from_text]
    F --> G[GenerationService.generate_from_text]
    G --> H[Get Default Model]
    G --> I[Set Seed]
    G --> J[Create Model Instance]
    J --> K[TextToMusicModel]
    K --> L1[Load Model]
    L1 --> L1a[Local Cache Check]
    L1 --> L1b[Download if Needed]
    L1 --> L1c[Move to Target Device]
    K --> L2[Prepare Input]
    L2 --> L2a[Tokenize Text]
    L2 --> L2b[Set Parameters]
    K --> L3[Model.generate]
    L3 --> L3a[Model Inference]
    L3a --> L3a1[Transformer Generation]
    L3a --> L3a2[Apply Conditioning]
    L3a --> L3a3[Sampling Strategy]
    L3 --> L3b[Post-processing]
    L3b --> L3b1[Audio Decoding]
    L3b --> L3b2[Normalization]
    L3 --> L4[Return Audio]
    L4 --> M[Audio Processor]
    M --> M1[Analyze Audio]
    M --> M2[Apply Effects]
    M --> M3[Format Audio]
    M --> N[Return Results]
    N --> O[Display in UI]
    O --> P[Playback Controls]
    O --> Q[Download Option]
    O --> R[Save to Library]
    R --> S[OutputService.save_audio_output]
    S --> S1[Create Metadata]
    S --> S2[Save Audio File]
    S --> S3[Create Visualizations]
    S --> S4[Update Registry]
```

### Audio-to-Music Generation Flow

```mermaid
flowchart TD
    A[User Input] --> B[Audio Input]
    B --> B1[Upload File]
    B --> B2[Record Audio]
    B --> B3[Select Library Item]
    A --> C[Text Prompt]
    A --> D[Mode Selection]
    D --> D1[Continuation]
    D --> D2[Style Transfer]
    D --> D3[Remix]
    D --> D4[Variation]
    A --> E[Model Selection]
    A --> F[Parameters]
    F --> F1[Duration]
    F --> F2[Temperature]
    F --> F3[Seed]
    F --> F4[Strength]
    F --> F5[Guidance Scale]
    B & C & D & E & F --> G[Generate Button]
    G --> H[generate_from_audio]
    H --> I[GenerationService.generate_from_audio]
    I --> J[Get Default Model]
    I --> K[Set Seed]
    I --> L[Create Model Instance]
    L --> M[AudioToMusicModel]
    M --> N[Load Model]
    M --> O[Process Audio Input]
    O --> O1[Load Audio]
    O --> O2[Resample]
    O --> O3[Extract Features]
    O --> O4[Create Conditioning]
    M --> P[Generate]
    P -->|Continuation| Q[continue_audio]
    P -->|Style Transfer| R[style_transfer]
    P -->|Remix| S[remix_audio]
    P -->|Variation| T[create_variation]
    Q & R & S & T --> U[Model Inference]
    U --> V[Post-processing]
    V --> W[Return Audio]
    W --> X[Display in UI]
    X --> Y[Save to Library]
    X --> Z[Audio Comparison UI]
    Z --> Z1[Original]
    Z --> Z2[Generated]
```

### MIDI-to-Audio Generation Flow

```mermaid
flowchart TD
    A[User Input] --> B[MIDI Input]
    B --> B1[Upload File]
    B --> B2[Create with Editor]
    B --> B3[Import from Library]
    A --> C[Text Prompt]
    C --> C1[Description]
    C --> C2[Genre/Style]
    C --> C3[Emotion]
    A --> D[Instrument Prompt]
    D --> D1[Instrument Selection]
    D --> D2[Ensemble Type]
    A --> E[Model Selection]
    A --> F[Parameters]
    F --> F1[Duration]
    F --> F2[Temperature]
    F --> F3[Seed]
    F --> F4[Complexity]
    B & C & D & E & F --> G[Generate Button]
    G --> H[generate_from_midi]
    H --> I[GenerationService.generate_from_midi]
    I --> J[Get Default Model]
    I --> K[Set Seed]
    I --> L[Create Model Instance]
    L --> M[MIDIToAudioModel]
    M --> N[Load Model]
    M --> O[Process MIDI Input]
    O --> O1[Parse MIDI]
    O --> O2[Extract Notes]
    O --> O3[Extract Key/Tempo]
    O --> O4[Create Features]
    M --> P{Function Type}
    P -->|Basic Render| Q[generate]
    P -->|Styled Render| R[render_with_style]
    P -->|Harmonize| S[harmonize]
    Q & R & S --> T[Model Inference]
    T --> U[Post-processing]
    U --> V[Return Audio]
    V --> W[Display in UI]
    W --> X[Save to Library]
    W --> Y[MIDI/Audio Visualization]
    Y --> Y1[Piano Roll]
    Y --> Y2[Waveform]
    Y --> Y3[Side-by-side]
```

### Image-to-Music Generation Flow (Planned)

```mermaid
flowchart TD
    A[User Input] --> B[Image Input]
    B --> B1[Upload File]
    B --> B2[Capture Camera]
    B --> B3[URL Input]
    A --> C[Text Guidance]
    C --> C1[Description Override]
    C --> C2[Style Instructions]
    A --> D[Model Selection]
    A --> E[Parameters]
    E --> E1[Duration]
    E --> E2[Temperature]
    E --> E3[Seed]
    E --> E4[Image Influence]
    E --> E5[Mood Emphasis]
    B & C & D & E --> F[Generate Button]
    F --> G[generate_from_image]
    G --> H[GenerationService.generate_from_image]
    H --> I[Get Default Model]
    H --> J[Set Seed]
    H --> K[Create Model Instance]
    K --> L[ImageToMusicModel]
    L --> M[Load Models]
    M --> M1[Image Encoder]
    M --> M2[Music Generator]
    L --> N[Process Image]
    N --> N1[Resize/Normalize]
    N --> N2[Extract Features]
    N --> N3[Scene Analysis]
    N --> N4[Object Detection]
    N --> N5[Mood Classification]
    L --> O[Generate Description]
    O --> O1[Image Captioning]
    O --> O2[Combine with User Text]
    L --> P[Generate Music]
    P --> Q[Create Conditioning]
    P --> R[Model Inference]
    R --> S[Post-processing]
    S --> T[Return Audio]
    T --> U[Display in UI]
    U --> V[Image+Audio View]
    U --> W[Save to Library]
```

### Video-to-Music Generation Flow (Planned)

```mermaid
flowchart TD
    A[User Input] --> B[Video Input]
    B --> B1[Upload File]
    B --> B2[URL Input]
    A --> C[Generation Style]
    C --> C1[Soundtrack]
    C --> C2[Scene-adaptive]
    C --> C3[Emotion-tracked]
    A --> D[Parameters]
    D --> D1[Duration Match]
    D --> D2[Scene Change Detection]
    D --> D3[Emotion Tracking]
    D --> D4[Audio-Visual Sync]
    B & C & D --> E[Generate Button]
    E --> F[generate_from_video]
    F --> G[Process Video]
    G --> G1[Extract Frames]
    G --> G2[Scene Detection]
    G --> G3[Motion Analysis]
    G --> G4[Emotion Analysis]
    F --> H[Create Segments]
    H --> H1[Identify Key Moments]
    H --> H2[Create Timeline]
    F --> I[Generate Per Segment]
    I --> I1[Frame to Image Model]
    I --> I2[Text Guidance Creation]
    I --> I3[Music Generation]
    F --> J[Combine Segments]
    J --> J1[Transition Smoothing]
    J --> J2[Audio Mastering]
    J --> K[Return Full Audio]
    K --> L[Display in UI]
    L --> M[Video+Audio Player]
    L --> N[Save to Library]
```

### Biosensor-to-Music Generation Flow (Future)

```mermaid
flowchart TD
    A[User Input] --> B[Biosensor Input]
    B --> B1[Heart Rate]
    B --> B2[EEG Data]
    B --> B3[Motion Data]
    B --> B4[GSR Data]
    A --> C[Configuration]
    C --> C1[Mapping Settings]
    C --> C2[Musical Style]
    C --> C3[Emotion Focus]
    A --> D[Parameters]
    D --> D1[Reactivity]
    D --> D2[Complexity]
    D --> D3[Duration]
    B & C & D --> E[Generate Button]
    E --> F[Process Biosensor Data]
    F --> F1[Filter Data]
    F --> F2[Feature Extraction]
    F --> F3[State Classification]
    E --> G[Parameter Mapping]
    G --> G1[Signal to Music Parameters]
    G --> G2[Emotional Mapping]
    G --> G3[Temporal Scaling]
    E --> H[Music Generation]
    H --> H1[Continuous Generation]
    H --> H2[Adaptive Parameters]
    H --> H3[Transition Management]
    H --> I[Return Audio]
    I --> J[Display in UI]
    J --> K[Biofeedback Visualization]
    K --> K1[Data Overlay]
    K --> K2[Correlation Display]
    J --> L[Save to Library]
```

### Multi-Modal Generation Flow (Planned)

```mermaid
flowchart TD
    A[User Input] --> B[Multiple Inputs]
    B --> B1[Text Input]
    B --> B2[Audio Input]
    B --> B3[MIDI Input]
    B --> B4[Image Input]
    A --> C[Modal Weights]
    C --> C1[Text Influence]
    C --> C2[Audio Influence]
    C --> C3[MIDI Influence]
    C --> C4[Image Influence]
    A --> D[Parameters]
    D --> D1[Fusion Strategy]
    D --> D2[Cross-modal Mapping]
    D --> D3[Common Parameters]
    B & C & D --> E[Generate Button]
    E --> F[MultiModalGenerationService]
    F --> G[Process Each Input]
    G --> G1[Text Processing]
    G --> G2[Audio Processing]
    G --> G3[MIDI Processing]
    G --> G4[Image Processing]
    F --> H[Feature Fusion]
    H --> H1[Early Fusion]
    H --> H2[Late Fusion]
    H --> H3[Cross-attention]
    F --> I[Generate Music]
    I --> I1[Combined Conditioning]
    I --> I2[Model Inference]
    I --> I3[Post-processing]
    I --> J[Return Audio]
    J --> K[Display in UI]
    K --> L[Multi-modal Visualization]
    K --> M[Save to Library]
```

---

## Model Service Flows

### Model Registry and Initialization Flow

```mermaid
flowchart TD
    A[ModelService] --> B[Initialize]
    B --> C[_initialize_default_models]
    C --> C1[Register Text-to-Music]
    C --> C2[Register Audio-to-Music]
    C --> C3[Register MIDI-to-Audio]
    C --> C4[Register Image-to-Music]
    B --> D[_scan_local_models]
    D --> D1[Scan Pretrained]
    D --> D2[Scan Finetuned]
    D --> D3[Load Metadata]
    D --> D4[Update Registry]
    A --> E[get_models_for_task]
    E --> E1[Filter by Task]
    E --> E2[Sort by Priority]
    A --> F[get_model_info]
    A --> G[is_model_available_locally]
    G --> G1[Check Cache Path]
    G --> G2[Check Requirements]
    A --> H[search_huggingface_models]
    H --> H1[Query API]
    H --> H2[Filter Results]
    H --> H3[Process Model Info]
    A --> I[download_model]
    I --> I1[Create Directory]
    I --> I2[Download Files]
    I --> I3[Verify Download]
    I --> I4[Update Registry]
    A --> J[get_default_model_for_task]
    A --> K[register_model]
    A --> L[create_model_instance]
    
    L --> M{model_class_name?}
    M -->|TextToMusicModel| N[Return TextToMusicModel]
    M -->|AudioToMusicModel| O[Return AudioToMusicModel]
    M -->|MIDIToAudioModel| P[Return MIDIToAudioModel]
    M -->|ImageToMusicModel| Q[Return ImageToMusicModel]
```

### Model Loading and Inference Flow

```mermaid
flowchart TD
    A[BaseModel] --> B[load]
    B --> B1[Check if Loaded]
    B --> B2[Get Model Path]
    B --> B3[Check Local Cache]
    B --> B4{Available Locally?}
    B4 -->|Yes| B5[Load from Disk]
    B4 -->|No| B6[Download from Hub]
    B --> B7[Move to Device]
    B --> B8[Update Metadata]
    
    A --> C[generate]
    C --> C1[Check if Loaded]
    C1 -->|No| C2[load]
    C1 -->|Yes| C3[Configure Parameters]
    C --> C4[Prepare Inputs]
    C --> C5[Run Inference]
    C --> C6[Process Outputs]
    C --> C7[Return Results]
    
    A --> D[save]
    D --> D1[Check if Loaded]
    D --> D2[Get Output Path]
    D --> D3[Create Directory]
    D --> D4[Save Model Files]
    D --> D5[Save Metadata]
    D --> D6[Return Path]
    
    A --> E[to]
    E --> E1[Set Device]
    E --> E2[Move Model]
    
    F[ModelOptimizations] --> F1[apply_torch_compile]
    F --> F2[quantize]
    F --> F3[set_kv_cache]
    F --> F4[batch_inference]
    
    G[ModelMixins] --> G1[PretrainedModelMixin]
    G --> G2[TorchModelMixin]
    G --> G3[TrainableModelMixin]
    G --> G4[ServableModelMixin]
```

### Model Creation and Customization Flow (Planned)

```mermaid
flowchart TD
    A[ModelCustomizationService] --> B[create_ensemble_model]
    B --> B1[Select Base Models]
    B --> B2[Define Weights]
    B --> B3[Create Fusion Strategy]
    B --> B4[Register Ensemble]
    
    A --> C[create_lora_adapter]
    C --> C1[Select Base Model]
    C --> C2[Define LoRA Config]
    C --> C3[Initialize Weights]
    C --> C4[Register Adapter]
    
    A --> D[create_custom_model]
    D --> D1[Define Architecture]
    D --> D2[Set Parameters]
    D --> D3[Initialize Weights]
    D --> D4[Register Model]
    
    A --> E[import_external_model]
    E --> E1[Validate Model]
    E --> E2[Create Wrapper]
    E --> E3[Register in System]
    
    A --> F[export_model]
    F --> F1[Format Selection]
    F --> F2[Optimization Options]
    F --> F3[Export Process]
    F --> F4[Verification]
```

---

## Data Processing Flows

### Audio Processing Flow

```mermaid
flowchart TD
    A[AudioProcessor] --> B[load_audio]
    B --> B1[Check Format]
    B --> B2[Open File]
    B --> B3[Read Data]
    B --> B4[Normalize]
    
    A --> C[save_audio]
    C --> C1[Format Selection]
    C --> C2[Create Directory]
    C --> C3[Write File]
    
    A --> D[convert_format]
    D --> D1[Load Source]
    D --> D2[Format Conversion]
    D --> D3[Save Target]
    
    A --> E[compute_features]
    E --> E1[Spectrogram]
    E --> E2[MFCC]
    E --> E3[Chroma]
    E --> E4[Onset Detection]
    
    A --> F[normalize_audio]
    F --> F1[Analyze Levels]
    F --> F2[Calculate Scaling]
    F --> F3[Apply Normalization]
    
    A --> G[segment_audio]
    G --> G1[Define Segments]
    G --> G2[Create Chunks]
    G --> G3[Apply Overlap]
    
    A --> H[apply_effects]
    H --> H1[Apply Chain]
    H --> H2[Reverb]
    H --> H3[EQ]
    H --> H4[Time/Pitch]
    
    A --> I[analyze_audio]
    I --> I1[Spectral Analysis]
    I --> I2[Temporal Analysis]
    I --> I3[Perceptual Analysis]
    I --> I4[Return Results]
```

### MIDI Processing Flow

```mermaid
flowchart TD
    A[MIDIProcessor] --> B[load_midi]
    B --> B1[Parse File]
    B --> B2[Create Score]
    
    A --> C[save_midi]
    C --> C1[Format Score]
    C --> C2[Write File]
    
    A --> D[extract_notes]
    D --> D1[Find All Notes]
    D --> D2[Extract Properties]
    D --> D3[Sort by Offset]
    
    A --> E[extract_chords]
    E --> E1[Find All Chords]
    E --> E2[Extract Properties]
    E --> E3[Sort by Offset]
    
    A --> F[extract_key]
    F --> F1[Analyze Score]
    F --> F2[Detect Key]
    
    A --> G[extract_tempo]
    G --> G1[Find Tempo Markings]
    G --> G2[Return Value]
    
    A --> H[transpose]
    H --> H1[Shift Pitches]
    H --> H2[Return New Score]
    
    A --> I[quantize]
    I --> I1[Set Grid]
    I --> I2[Adjust Note Timings]
    I --> I3[Return Quantized Score]
    
    A --> J[extract_melody]
    J --> J1[Heuristic Analysis]
    J --> J2[Find Top Line]
    J --> J3[Create Melody Sequence]
    
    A --> K[midi_to_pianoroll]
    K --> K1[Create Grid]
    K --> K2[Populate Notes]
    K --> K3[Return Array]
    
    A --> L[tokens_to_midi]
    L --> L1[Parse Tokens]
    L --> L2[Create Events]
    L --> L3[Build MIDI File]
```

### Image Processing Flow (Planned)

```mermaid
flowchart TD
    A[ImageProcessor] --> B[load_image]
    B --> B1[Open File]
    B --> B2[Resize/Crop]
    B --> B3[Normalize]
    
    A --> C[extract_features]
    C --> C1[Color Analysis]
    C --> C2[Content Detection]
    C --> C3[Style Features]
    C --> C4[Emotion Classification]
    
    A --> D[image_to_embedding]
    D --> D1[Load Vision Model]
    D --> D2[Generate Embedding]
    D --> D3[Process Features]
    
    A --> E[generate_caption]
    E --> E1[Load Captioning Model]
    E --> E2[Generate Description]
    E --> E3[Format Output]
    
    A --> F[segment_image]
    F --> F1[Detect Objects]
    F --> F2[Create Foreground/Background]
    F --> F3[Return Segments]
    
    A --> G[analyze_scene]
    G --> G1[Scene Classification]
    G --> G2[Composition Analysis]
    G --> G3[Motion Estimation]
    G --> G4[Dominant Elements]
```

### Dataset Processing Flow (Planned)

```mermaid
flowchart TD
    A[DatasetProcessor] --> B[create_dataset]
    B --> B1[Define Structure]
    B --> B2[Set Parameters]
    B --> B3[Initialize Storage]
    
    A --> C[add_data]
    C --> C1[Process Input]
    C --> C2[Extract Features]
    C --> C3[Store Entry]
    C --> C4[Update Index]
    
    A --> D[create_dataloader]
    D --> D1[Set Batch Size]
    D --> D2[Define Transforms]
    D --> D3[Configure Options]
    D --> D4[Return DataLoader]
    
    A --> E[split_dataset]
    E --> E1[Training Split]
    E --> E2[Validation Split]
    E --> E3[Test Split]
    
    A --> F[balance_dataset]
    F --> F1[Analyze Distribution]
    F --> F2[Apply Balancing]
    F --> F3[Verify Balance]
    
    A --> G[augment_data]
    G --> G1[Audio Augmentation]
    G --> G2[Pitch/Tempo Shift]
    G --> G3[Add Noise]
    G --> G4[Apply Effects]
    
    A --> H[export_dataset]
    H --> H1[Format Selection]
    H --> H2[Package Files]
    H --> H3[Create Metadata]
    H --> H4[Save Bundle]
```

---

## Training Service Flows

### Model Training Flow (Planned)

```mermaid
flowchart TD
    A[TrainingService] --> B[setup_training]
    B --> B1[Select Base Model]
    B --> B2[Configure Training]
    B --> B3[Prepare Dataset]
    B --> B4[Initialize Environment]
    
    A --> C[train_model]
    C --> C1[Initialize Trainer]
    C --> C2[Setup Optimizer]
    C --> C3[Configure Callbacks]
    C --> C4[Start Training Loop]
    C --> C5[Evaluate Progress]
    C --> C6[Save Checkpoints]
    
    A --> D[fine_tune_model]
    D --> D1[Initialize LoRA]
    D --> D2[Freeze Base Model]
    D --> D3[Train Adapter]
    D --> D4[Merge Parameters]
    
    A --> E[evaluate_model]
    E --> E1[Generate Samples]
    E --> E2[Calculate Metrics]
    E --> E3[Compare Baselines]
    E --> E4[Produce Report]
    
    A --> F[export_trained_model]
    F --> F1[Package Model]
    F --> F2[Create Metadata]
    F --> F3[Register in Service]
    F --> F4[Save to Disk]
```

### Cloud Training Flow (Planned)

```mermaid
flowchart TD
    A[CloudTrainingService] --> B[setup_cloud_environment]
    B --> B1[Select Provider]
    B --> B2[Configure Instance]
    B --> B3[Setup Storage]
    B --> B4[Initialize Environment]
    
    A --> C[upload_dataset]
    C --> C1[Compress Data]
    C --> C2[Upload Files]
    C --> C3[Verify Transfer]
    
    A --> D[launch_training_job]
    D --> D1[Create Job Definition]
    D --> D2[Set Parameters]
    D --> D3[Launch Job]
    D --> D4[Monitor Progress]
    
    A --> E[check_status]
    E --> E1[Query Provider API]
    E --> E2[Get Metrics]
    E --> E3[Update Status]
    
    A --> F[download_results]
    F --> F1[Check Completion]
    F --> F2[Download Files]
    F --> F3[Verify Integrity]
    F --> F4[Import to Local]
    
    A --> G[terminate_resources]
    G --> G1[Stop Jobs]
    G --> G2[Delete Temporary Files]
    G --> G3[Release Instances]
```

### Experiment Tracking Flow (Planned)

```mermaid
flowchart TD
    A[ExperimentTracker] --> B[create_experiment]
    B --> B1[Set Name/ID]
    B --> B2[Define Parameters]
    B --> B3[Initialize Storage]
    
    A --> C[log_metrics]
    C --> C1[Record Values]
    C --> C2[Calculate Statistics]
    C --> C3[Update History]
    
    A --> D[log_samples]
    D --> D1[Generate Examples]
    D --> D2[Store Examples]
    D --> D3[Create Index]
    
    A --> E[compare_experiments]
    E --> E1[Load Experiments]
    E --> E2[Calculate Differences]
    E --> E3[Generate Visualizations]
    E --> E4[Create Report]
    
    A --> F[export_results]
    F --> F1[Format Selection]
    F --> F2[Compile Data]
    F --> F3[Create Visualizations]
    F --> F4[Save Bundle]
```

---

## UI Flows

### Gradio UI Component Architecture

```mermaid
flowchart TD
    A[create_ui] --> B[Get Services]
    B --> B1[generation_service]
    B --> B2[model_service]
    B --> B3[output_service]
    B --> B4[training_service]
    
    A --> C[Get Available Models]
    C --> C1[Text Models]
    C --> C2[Audio Models]
    C --> C3[MIDI Models]
    C --> C4[Image Models]
    
    A --> D[Create Gradio Blocks]
    D --> E[Text to Music Tab]
    E --> E1[Text Input Components]
    E --> E2[Parameter Components]
    E --> E3[Generation Components]
    E --> E4[Output Components]
    
    D --> F[Audio to Music Tab]
    F --> F1[Audio Input Components]
    F --> F2[Mode Selection]
    F --> F3[Parameter Components]
    F --> F4[Generation Components]
    F --> F5[Output Components]
    
    D --> G[MIDI to Music Tab]
    G --> G1[MIDI Input Components]
    G --> G2[Instrument Selection]
    G --> G3[Parameter Components]
    G --> G4[Generation Components]
    G --> G5[Output Components]
    
    D --> H[Image to Music Tab]
    H --> H1[Image Input Components]
    H --> H2[Text Guidance]
    H --> H3[Parameter Components]
    H --> H4[Generation Components]
    H --> H5[Output Components]
    
    D --> I[Training Tab]
    I --> I1[Dataset Management]
    I --> I2[Model Selection]
    I --> I3[Training Parameters]
    I --> I4[Training Controls]
    I --> I5[Progress Display]
    
    D --> J[Library Tab]
    J --> J1[Generation History]
    J --> J2[Output Browser]
    J --> J3[Search/Filter]
    J --> J4[Playback Controls]
    
    D --> K[Settings Tab]
    K --> K1[General Settings]
    K --> K2[Model Settings]
    K --> K3[Processing Settings]
    K --> K4[Interface Settings]
```

### Advanced UI Interaction Flows (Planned)

```mermaid
flowchart TD
    A[Advanced UI] --> B[Real-time Parameter Adjustment]
    B --> B1[Parameter Controls]
    B --> B2[Live Updating]
    B --> B3[Parameter Presets]
    
    A --> C[Interactive Output Management]
    C --> C1[Version History]
    C --> C2[Comparison View]
    C --> C3[Edit Metadata]
    C --> C4[Export Options]
    
    A --> D[Multi-step Generation]
    D --> D1[Generation Pipeline]
    D --> D2[Intermediate Results]
    D --> D3[Step Controls]
    D --> D4[Pipeline Templates]
    
    A --> E[Visualization Tools]
    E --> E1[Waveform Analysis]
    E --> E2[Spectral Display]
    E --> E3[Piano Roll View]
    E --> E4[Parameter Visualization]
    
    A --> F[Collaborative Features]
    F --> F1[Share Generation]
    F --> F2[Import Settings]
    F --> F3[Export Settings]
    F --> F4[Template Library]
```

### Desktop Application UI Flow (Planned)

```mermaid
flowchart TD
    A[Desktop App] --> B[Startup Flow]
    B --> B1[Launch Process]
    B --> B2[Load Resources]
    B --> B3[Initialize Services]
    B --> B4[Restore State]
    
    A --> C[Workspace Management]
    C --> C1[Project Creation]
    C --> C2[Session Management]
    C --> C3[Workspace Settings]
    
    A --> D[Integration Points]
    D --> D1[File System Access]
    D --> D2[Audio Device Integration]
    D --> D3[MIDI Device Integration]
    D --> D4[External Tool Integration]
    
    A --> E[Offline Mode]
    E --> E1[Model Cache]
    E --> E2[Content Library]
    E --> E3[Local Processing]
    
    A --> F[Advanced Features]
    F --> F1[Keyboard Shortcuts]
    F --> F2[Batch Processing]
    F --> F3[Automated Workflows]
    F --> F4[System Tray Operation]
```

---

## Integration Flows

### DAW Integration Flow (Planned)

```mermaid
flowchart TD
    A[DAW Integration] --> B[Plugin Formats]
    B --> B1[VST3 Plugin]
    B --> B2[AU Plugin]
    B --> B3[AAX Plugin]
    B --> B4[Standalone App]
    
    A --> C[Audio Integration]
    C --> C1[Audio Output]
    C --> C2[Audio Routing]
    C --> C3[Sample Rate Sync]
    C --> C4[Audio Rendering]
    
    A --> D[MIDI Integration]
    D --> D1[MIDI Input]
    D --> D2[MIDI Output]
    D --> D3[MIDI Clock Sync]
    D --> D4[MIDI Learn]
    
    A --> E[State Management]
    E --> E1[Save Preset]
    E --> E2[Load Preset]
    E --> E3[Plugin State]
    E --> E4[Automation]
    
    A --> F[UI Integration]
    F --> F1[Plugin Window]
    F --> F2[Parameter Display]
    F --> F3[Automation Lanes]
    F --> F4[Control Surface]
```

### Content Creation Platform Integration (Planned)

```mermaid
flowchart TD
    A[Content Platform Integration] --> B[Video Editing]
    B --> B1[Adobe Premiere]
    B --> B2[Final Cut Pro]
    B --> B3[DaVinci Resolve]
    
    A --> C[Game Engines]
    C --> C1[Unity Integration]
    C --> C2[Unreal Engine]
    C --> C3[Godot Engine]
    
    A --> D[API Services]
    D --> D1[REST API]
    D --> D2[GraphQL API]
    D --> D3[WebSocket Events]
    
    A --> E[Export Formats]
    E --> E1[Video Soundtrack]
    E --> E2[Game Audio Assets]
    E --> E3[Streaming Content]
    
    A --> F[Dynamic Audio]
    F --> F1[Adaptive Music]
    F --> F2[Procedural Generation]
    F --> F3[Interactive Music]
```

### Third-Party Model Integration (Planned)

```mermaid
flowchart TD
    A[Third-Party Model Integration] --> B[Model Sources]
    B --> B1[Hugging Face Hub]
    B --> B2[GitHub Models]
    B --> B3[Custom Models]
    
    A --> C[Model Framework Adapters]
    C --> C1[PyTorch Adapter]
    C --> C2[TensorFlow Adapter]
    C --> C3[ONNX Adapter]
    C --> C4[TFLite Adapter]
    
    A --> D[Configuration Interface]
    D --> D1[Model Import]
    D --> D2[Parameter Mapping]
    D --> D3[Version Management]
    
    A --> E[Integration Testing]
    E --> E1[Validation Suite]
    E --> E2[Performance Testing]
    E --> E3[Output Quality]
    
    A --> F[Deployment Pipeline]
    F --> F1[Packaging]
    F --> F2[Documentation]
    F --> F3[Release Management]
```

---

## Deployment Flows

### Local Deployment Flow

```mermaid
flowchart TD
    A[Local Deployment] --> B[Environment Setup]
    B --> B1[Python Environment]
    B --> B2[Dependencies]
    B --> B3[GPU Setup]
    B --> B4[Audio Config]
    
    A --> C[Installation Methods]
    C --> C1[Pip Installation]
    C --> C2[Git Clone]
    C --> C3[Docker Container]
    C --> C4[Desktop App]
    
    A --> D[First-Run Experience]
    D --> D1[Model Download]
    D --> D2[Initial Configuration]
    D --> D3[Tutorial]
    
    A --> E[Resource Management]
    E --> E1[Disk Space]
    E --> E2[Memory Usage]
    E --> E3[GPU Resources]
    E --> E4[Network Usage]
    
    A --> F[Update Flow]
    F --> F1[Check for Updates]
    F --> F2[Download Update]
    F --> F3[Apply Update]
    F --> F4[Migrate Settings]
```

### Cloud Deployment Flow (Planned)

```mermaid
flowchart TD
    A[Cloud Deployment] --> B[Service Options]
    B --> B1[Web Service]
    B --> B2[Serverless]
    B --> B3[Container Service]
    
    A --> C[Infrastructure Setup]
    C --> C1[Compute Resources]
    C --> C2[Storage Resources]
    C --> C3[Network Config]
    C --> C4[Security Settings]
    
    A --> D[Scaling Configuration]
    D --> D1[Autoscaling]
    D --> D2[Load Balancing]
    D --> D3[Resource Limits]
    
    A --> E[Monitoring & Logging]
    E --> E1[Performance Metrics]
    E --> E2[Error Tracking]
    E --> E3[Usage Analytics]
    E --> E4[Alerting]
    
    A --> F[API Management]
    F --> F1[Endpoint Configuration]
    F --> F2[Authentication]
    F --> F3[Rate Limiting]
    F --> F4[Documentation]
```

### Edge Deployment Flow (Future)

```mermaid
flowchart TD
    A[Edge Deployment] --> B[Device Targets]
    B --> B1[Mobile Devices]
    B --> B2[Embedded Systems]
    B --> B3[IoT Devices]
    
    A --> C[Model Optimization]
    C --> C1[Quantization]
    C --> C2[Pruning]
    C --> C3[Architecture Optimization]
    C --> C4[Knowledge Distillation]
    
    A --> D[Runtime Environments]
    D --> D1[TFLite Runtime]
    D --> D2[ONNX Runtime]
    D --> D3[PyTorch Mobile]
    D --> D4[Custom Runtime]
    
    A --> E[Performance Profiling]
    E --> E1[Memory Analysis]
    E --> E2[Latency Measurement]
    E --> E3[Battery Impact]
    E --> E4[Thermal Impact]
    
    A --> F[Integration Frameworks]
    F --> F1[React Native]
    F --> F2[Flutter]
    F --> F3[Native SDK]
    F --> F4[Web Assembly]
```

This document provides a comprehensive view of both current and planned flows in the Disco Musica application, serving as a roadmap for development and a reference for understanding the system architecture.